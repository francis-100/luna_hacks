# Business Understanding
## Who is the client?
- The target user of this machine learning model is a farmer.
## Needs of the client
1. To be able to make informed decisions regarding crop planting and harvesting.
2. To improve on food security.
3. To reduce on food waste.
4. To increase income for the farmers.
5. To be able to improve on farming techniques.
6. To be able to choose on better irrigation systems.
7. To be able to make informed decisions on the type of plant based on the soil quality.

## Client engagement process
 1. Machine learning team initially meet with the farmers.
 2. Data collection to understand the problem statement and the project scope and objectives.
 3. Analyzing and evaluating farmers information. 
 4. Develop a personalized strategy so as to collaborate with the clients along the way. 
 5. Implementing solutions for the risk management.
 6. Monitoring appropriate areas where the maize crop can yield.


## Project Objectives
* To develop a machine learning model that predicts crop yields in Sub-Saharan Africa based on various factors such as:
    - Weather patterns
    - Soil quality
    - Irrigation systems
    - Farming techniques
# Data Acquisition
## Source Systems
-The data source for this project was obtained from various Sub-Saharan countries. This data have been analysed in GYGA which is widely used in collecting, storing and managing data. 
-The xlsx file consits of three sheets specifying the country, climate zone and station.
 1. GygaRainfedMaizeSubSaharanAfrica.xlsx

## Data Acquisition process
-Data Gathering: Gathering data from the source systems was the first phase in the data acquisition process. The information was accessed by any user and shared form of an excel format.

-Data Extraction: After the data had been shared we gathered it by downloading it to our machines. To make using the data during the data analysis process easier, the data was exported to pandas dataframe .

-Data Cleaning: To make sure the data was of the highest quality and prepared for analysis, the data underwent cleaning before being loaded into the working environment using pandas. Checking the data for duplicates, missing numbers, and inconsistencies was part of the cleaning procedure.

-Data Loading: Following data cleansing, pandas was used to load the data into the working environment. Data frames, a type of pandas data structure that facilitates effective data manipulation and analysis, were used to load the data.

-Data Preparation: The data was further prepared for analysis after it had been imported into the data frames. This required changing column names, eliminating extra columns, and converting the data's data types.

-Data Analysis: When the data had been loaded and formatted, data analysis was the following stage in order to find trends, patterns, and insights. Data visualization, machine learning, and statistical methodologies were all used to accomplish this.

# Exploratory Data Analysis


# Data Cleaning

# Feature Engineering

# Model Development

# Model Evaluation

# Model Deployment

# Challenges

































   

